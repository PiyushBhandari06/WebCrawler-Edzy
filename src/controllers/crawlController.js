import { crawlState } from "../state/crawlState.js";
import { crawlSitemap } from "../crawler/crawlSitemap.js";
import { buildIncomingLinks } from "../graph/buildIncomingLinks.js";

export const startCrawl = async (req, res) => {
  // 1. Prevent double execution
  if (crawlState.isCrawling) {
    return res.status(409).json({
      message: "Crawl already in progress",
    });
  }

  // 2. Mark crawl as started
  crawlState.isCrawling = true;

  // 3. Respond immediately
  res.json({
    message: "Crawl started successfully",
  });

  // 4. Run crawl asynchronously (in background)
  (async () => {
    try {
      console.log("ğŸš€ Crawl started");
      await crawlSitemap();

      console.log("ğŸ” Starting incoming link computation");
      await buildIncomingLinks();

      console.log("Incoming link computation completed ğŸ‰");

      console.log("Crawl pipeline completed !ğŸ‰");

    } catch (error) {
      console.error("âŒ Crawl failed:", error.message);

    } finally {
      crawlState.isCrawling = false;
      console.log("Crawl state has been reset");
      
    }
  })();
};
